{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: langchain_ollama in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (0.3.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (3.11.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain_community) (2.7.1)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain_ollama) (0.4.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\langchain\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_community langchain_ollama langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(\n",
    "    model=\"llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\"  # Ensure Ollama is running locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 1\n",
      "Sample Document: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load a text document\n",
    "file_path = \"../../00-example_data/state_of_the_union.txt\"\n",
    "document_loader = TextLoader(file_path)\n",
    "raw_documents = document_loader.load()\n",
    "\n",
    "print(\"Number of documents loaded:\", len(raw_documents))\n",
    "print(\"Sample Document:\", raw_documents[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 49\n",
      "Sample Chunk: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. \n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Split text into manageable chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "print(\"Number of chunks created:\", len(chunks))\n",
    "print(\"Sample Chunk:\", chunks[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings generated: 49\n",
      "First Chunk Embedding (first 5 values): [0.003959221, 0.012483264, -0.011752846, -0.010141397, -0.0100551145]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each chunk\n",
    "chunk_embeddings = [embedding_model.embed_query(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "print(\"Number of embeddings generated:\", len(chunk_embeddings))\n",
    "print(\"First Chunk Embedding (first 5 values):\", chunk_embeddings[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in vector store: 49\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Convert chunks to LangChain Documents\n",
    "documents = [Document(page_content=chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# Create an in-memory vector store\n",
    "vector_store = InMemoryVectorStore.from_documents(documents, embedding_model)\n",
    "\n",
    "print(\"Number of documents in vector store:\", len(vector_store.store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents:\n",
      "Result 1:\n",
      "To all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And I’m taking robust action to make sure the pain o\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "We are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \n",
      "\n",
      "Tonight I say to the Russian oligarchs and corrupt leaders who have b\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It i\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a query\n",
    "query = \"What is the state of the union?\"\n",
    "\n",
    "# Search for similar chunks\n",
    "similar_docs = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Most similar documents:\")\n",
    "for i, doc in enumerate(similar_docs, start=1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(doc.page_content[:200])  # Print first 200 characters\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
