{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-openai langchain-ollama chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chroma-hnswlib in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (0.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from chroma-hnswlib) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chroma-hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "underlying_embeddings = OllamaEmbeddings(\n",
    "    #model=\"nomic-embed-text:latest\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\",  # Replace with your Ollama base URL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings, store, namespace=\"llama3_2_latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in cache before loading: []\n"
     ]
    }
   ],
   "source": [
    "# Verify the keys in the cache\n",
    "print(\"Keys in cache before loading:\", list(store.yield_keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text document\n",
    "file_path = \"../../00-example_data/state_of_the_union.txt\"\n",
    "raw_documents = TextLoader(file_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and caching embeddings...\n",
      "Document 1: Embedding cached.\n",
      "Document 2: Embedding cached.\n",
      "Document 3: Embedding cached.\n",
      "Document 4: Embedding cached.\n",
      "Document 5: Embedding cached.\n",
      "Document 6: Embedding cached.\n",
      "Document 7: Embedding cached.\n",
      "Document 8: Embedding cached.\n",
      "Document 9: Embedding cached.\n",
      "Document 10: Embedding cached.\n",
      "Document 11: Embedding cached.\n",
      "Document 12: Embedding cached.\n",
      "Document 13: Embedding cached.\n",
      "Document 14: Embedding cached.\n",
      "Document 15: Embedding cached.\n",
      "Document 16: Embedding cached.\n",
      "Document 17: Embedding cached.\n",
      "Document 18: Embedding cached.\n",
      "Document 19: Embedding cached.\n",
      "Document 20: Embedding cached.\n",
      "Document 21: Embedding cached.\n",
      "Document 22: Embedding cached.\n",
      "Document 23: Embedding cached.\n",
      "Document 24: Embedding cached.\n",
      "Document 25: Embedding cached.\n",
      "Document 26: Embedding cached.\n",
      "Document 27: Embedding cached.\n",
      "Document 28: Embedding cached.\n",
      "Document 29: Embedding cached.\n",
      "Document 30: Embedding cached.\n",
      "Document 31: Embedding cached.\n",
      "Document 32: Embedding cached.\n",
      "Document 33: Embedding cached.\n",
      "Document 34: Embedding cached.\n",
      "Document 35: Embedding cached.\n",
      "Document 36: Embedding cached.\n",
      "Document 37: Embedding cached.\n",
      "Document 38: Embedding cached.\n",
      "Document 39: Embedding cached.\n",
      "Document 40: Embedding cached.\n",
      "Document 41: Embedding cached.\n",
      "Document 42: Embedding cached.\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings and verify caching without using vector store\n",
    "print(\"Generating and caching embeddings...\")\n",
    "for i, doc in enumerate(documents):\n",
    "    embedding = cached_embedder.embed_query(doc.page_content)\n",
    "    print(f\"Document {i+1}: Embedding cached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize ChromaDB vector store\n",
    "vector_store = Chroma.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in cache after embedding: ['llama3_2_latest01dbc21f-5e4c-5fb5-8d13-517dbe7a32d4', 'llama3_2_latest059eb9ff-c4c8-5ceb-8bf9-0d3d02a92b44', 'llama3_2_latest0fc1ede2-407a-5e14-8f8f-5642214263f5', 'llama3_2_latest1297d37a-2bc1-5e19-bf13-6c950f075062', 'llama3_2_latest17a6727d-8916-54eb-b196-ec9c9d6ca472', 'llama3_2_latest1d203ac6-0e5c-5e99-9c20-884b3206ba18', 'llama3_2_latest20c8f906-bea3-5e8c-b01a-e5ecfa990007', 'llama3_2_latest24610cdc-5e53-577d-8142-5f9c16afbd22', 'llama3_2_latest280a9fbe-0d67-50df-9796-d781d74a0ea4', 'llama3_2_latest2b51a7dd-babe-5c36-8930-3baa92a1130a', 'llama3_2_latest305efb5c-3f01-5657-bcf2-2b92fb1747ca', 'llama3_2_latest3f32125d-8e2c-5e8f-8ea1-0e4fe633c9f5', 'llama3_2_latest3f7b9f1f-79ae-55e3-966a-d0ec952476ed', 'llama3_2_latest464862c8-03d2-5854-b32c-65a075e612a2', 'llama3_2_latest4e5734dd-6470-5d9e-a7b8-468ebc563c4e', 'llama3_2_latest5ba09d7e-6a58-5c76-b038-5d8636e5ea25', 'llama3_2_latest5fc0d904-bd80-52da-95c9-441015bfb438', 'llama3_2_latest614d7cf6-46f1-52fa-9d3a-740c39e7a20e', 'llama3_2_latest61d8953c-db8d-5c66-9b74-9cdfc9dd8089', 'llama3_2_latest6d6cb8fc-721a-5a4c-bfe9-c83d2920c2bb', 'llama3_2_latest704c76af-3696-5383-9858-6585616669ef', 'llama3_2_latest8061c36f-1bb7-5be5-9de2-afbed11ff5f2', 'llama3_2_latest812fdf9a-5fca-504e-9890-b93dd6a8b22c', 'llama3_2_latest81426526-23fe-58be-9e84-6c7c72c8ca9a', 'llama3_2_latest87e9d490-3926-58e1-9159-0e0280d7c266', 'llama3_2_latest8aea1138-d3d3-5c93-afd8-3284fe99cc1d', 'llama3_2_latest9c15af4c-0e3b-5020-926f-752f448be568', 'llama3_2_latesta0a3f526-9883-5998-9062-974c42470389', 'llama3_2_latesta11929e8-e117-5e77-b367-1e12dc3b44b0', 'llama3_2_latesta5ef11e4-0474-5725-8d80-81c91943b37f', 'llama3_2_latestabeef673-2b2a-5614-b612-d4ff3ef54c23', 'llama3_2_latestb35583f7-c036-5cae-b60b-394754b7d149', 'llama3_2_latestb4af1c6d-dce3-5a2c-90fc-4df7f5bb3e5a', 'llama3_2_latestb793db35-a909-5ba0-8c51-314dc776017d', 'llama3_2_latestdeb2fdfe-f777-5739-bf8e-6ab5bc4b97bb', 'llama3_2_lateste0a36554-0f77-5b95-b300-469780b62d25', 'llama3_2_lateste4ad20ef-dfaa-5916-9459-f90c6d8e8159', 'llama3_2_lateste63d3826-4fe9-5f42-bb1d-393b148383ba', 'llama3_2_latested199159-c1cd-5597-9757-f80498e8f17b', 'llama3_2_latested934225-a8bf-5fde-98b4-844cd841c041', 'llama3_2_latestf95efe7b-65ad-587b-93f2-e76fb91511ec', 'llama3_2_latestfb1e9c39-799f-590a-8ceb-4ee39793d18c']\n"
     ]
    }
   ],
   "source": [
    "# Verify cache content after embedding generation\n",
    "print(\"Keys in cache after embedding:\", list(store.yield_keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
