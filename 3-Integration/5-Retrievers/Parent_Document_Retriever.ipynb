{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6e74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d17af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ee23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Configure Ollama LLM\n",
    "ollama_llm = OllamaLLM(\n",
    "    model=\"llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Configure embedding model\n",
    "ollama_embedding = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:latest\",  # Correct parameter name is `model`\n",
    "    base_url=\"http://localhost:11434\",  # Base URL for the Ollama service\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604ff981",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    TextLoader(\"../../00-example_data/paul_graham_essay.txt\"),\n",
    "    TextLoader(\"../../00-example_data/state_of_the_union.txt\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a8b2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the child documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=ollama_embedding\n",
    ")\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b107935",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b97b7",
   "metadata": {},
   "source": [
    "This should yield two keys, because we added two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895d62b",
   "metadata": {},
   "source": [
    "Let's now call the vector store search functionality - we should see that it returns small chunks (since we're storing the small chunks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b261c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"justice breyer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8ed5a",
   "metadata": {},
   "source": [
    "Let's now retrieve from the overall retriever. This should return large documents - since it returns the documents where the smaller chunks are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "419a91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"justice breyer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f813a5",
   "metadata": {},
   "source": [
    "#### Retrieving larger chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6f9a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the parent documents\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=ollama_embedding\n",
    ")\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19478ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe16e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad3c8c",
   "metadata": {},
   "source": [
    "We can see that there are much more than two documents now - these are the larger chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d81886",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaef673",
   "metadata": {},
   "source": [
    "Let's make sure the underlying vector store still retrieves the small chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c859de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"justice breyer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffa2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3202df",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"justice breyer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
