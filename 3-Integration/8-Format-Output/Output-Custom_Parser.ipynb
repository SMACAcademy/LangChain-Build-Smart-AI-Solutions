{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize Ollama with a deterministic response\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:latest\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'M JUST A LANGUAGE MODEL, SO i DON'T HAVE EMOTIONS OR FEELINGS LIKE HUMANS DO. hOWEVER, i'M FUNCTIONING PROPERLY AND READY TO ASSIST YOU WITH ANY QUESTIONS OR TASKS YOU MAY HAVE! hOW CAN i HELP YOU TODAY?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a simple case-inverting parser\n",
    "def parse(ai_message: AIMessage) -> str:\n",
    "    \"\"\"Parse the AI message by inverting case.\"\"\"\n",
    "    return ai_message.content.swapcase()\n",
    "\n",
    "# Wrap the function in RunnableLambda\n",
    "parse = RunnableLambda(parse)\n",
    "\n",
    "# Chain model with parser\n",
    "chain = llm | parse\n",
    "\n",
    "# Invoke the model\n",
    "response = chain.invoke(\"Hello, how are you?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hERE | 'S |  ONE | :\n",
      "\n",
      " | dID |  YOU |  KNOW |  THAT |  HONEY |  NEVER |  SPO | ILS | ? |  aRCHAE | OLOGISTS |  HAVE |  FOUND |  POTS |  OF |  HONEY |  IN |  ANCIENT |  eGYPTIAN |  TOM | BS |  THAT |  ARE |  OVER |   | 3 | , | 000 |  YEARS |  OLD |  AND |  STILL |  PERFECTLY |  EDIBLE | ! |  hONEY | 'S |  UNIQUE |  COMPOSITION | , |  WITH |  ITS |  LOW |  MOISTURE |  CONTENT |  AND |  ACIDIC |  Ph | , |  MAKES |  IT |  AN |  IDEAL |  PRES | ERVATIVE | . |  iT | 'S |  ALSO |  A |  NATURAL |  ANTIB | ACTERIAL |  AGENT | , |  WHICH |  HELPS |  TO |  PREVENT |  THE |  GROWTH |  OF |  BACTERIA |  AND |  OTHER |  MICRO | ORGANISMS |  THAT |  CAN |  CAUSE |  SPOIL | AGE | . |  sO | , |  IF |  YOU |  EVER |  FIND |  YOURSELF |  IN |  ANCIENT |  eGYPT | , |  JUST |  GRAB |  A |  JAR |  OF |  HONEY |  FROM |  THE |  TOMB |  â€“ |  IT | 'LL |  STILL |  BE |  SWEET | ! |  | "
     ]
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "\n",
    "# Define a streaming parser\n",
    "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
    "    \"\"\"Parse incoming message chunks and invert case.\"\"\"\n",
    "    for chunk in chunks:\n",
    "        yield chunk.content.swapcase()\n",
    "\n",
    "# Wrap it in RunnableGenerator\n",
    "streaming_parse = RunnableGenerator(streaming_parse)\n",
    "\n",
    "# Chain with Ollama\n",
    "chain = llm | streaming_parse\n",
    "\n",
    "# Stream the output\n",
    "for chunk in chain.stream(\"Tell me a fun fact\"):\n",
    "    print(chunk, end=\" | \", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "Error: Expected output to be YES or NO, but got 'MAYBETEST'.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "# Define a boolean parser\n",
    "class BooleanOutputParser(BaseOutputParser[bool]):\n",
    "    \"\"\"Custom parser that converts YES/NO to Boolean.\"\"\"\n",
    "    \n",
    "    true_val: str = \"YES\"\n",
    "    false_val: str = \"NO\"\n",
    "\n",
    "    def parse(self, text: str) -> bool:\n",
    "        \"\"\"Parse the text output into a boolean.\"\"\"\n",
    "        cleaned_text = text.strip().upper()\n",
    "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
    "            raise OutputParserException(\n",
    "                f\"Expected output to be {self.true_val} or {self.false_val}, but got '{cleaned_text}'.\"\n",
    "            )\n",
    "        return cleaned_text == self.true_val.upper()\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"boolean_output_parser\"\n",
    "\n",
    "# Create parser instance\n",
    "parser = BooleanOutputParser()\n",
    "\n",
    "# Test the parser\n",
    "print(parser.invoke(\"YES\"))  # Output: True\n",
    "print(parser.invoke(\"NO\"))   # Output: False\n",
    "\n",
    "# Trigger exception\n",
    "try:\n",
    "    print(parser.invoke(\"MAYBETEST\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'M AN ARTIFICIAL INTELLIGENCE DESIGNED TO PROVIDE INFORMATION AND ASSIST WITH TASKS, BUT i DON'T HAVE PERSONAL EXPERIENCES OR EMOTIONS LIKE HUMANS DO.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import BaseGenerationOutputParser\n",
    "from langchain_core.outputs import ChatGeneration, Generation\n",
    "from typing import List\n",
    "\n",
    "# Define an advanced parser\n",
    "class StrInvertCase(BaseGenerationOutputParser[str]):\n",
    "    \"\"\"Parser that inverts case in responses.\"\"\"\n",
    "    \n",
    "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n",
    "        \"\"\"Parse model output and swap case.\"\"\"\n",
    "        if len(result) != 1:\n",
    "            raise NotImplementedError(\"This parser only works with single-generation outputs.\")\n",
    "        \n",
    "        generation = result[0]\n",
    "        \n",
    "        if not isinstance(generation, ChatGeneration):\n",
    "            raise OutputParserException(\"This parser only works with chat generation.\")\n",
    "\n",
    "        return generation.message.content.swapcase()\n",
    "\n",
    "# Chain with Ollama\n",
    "chain = llm | StrInvertCase()\n",
    "\n",
    "# Invoke the model\n",
    "response = chain.invoke(\"Tell me a short sentence about yourself.\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
