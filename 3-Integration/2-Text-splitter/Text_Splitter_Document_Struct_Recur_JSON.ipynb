{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f335e05-e5ae-44cc-899d-749aa9031a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3390ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "# This is a large nested json object and will be loaded as a python dict\n",
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfe2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69250bc6-c0f5-40d0-b8ba-7a349236bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively split json data - If you need to access/manipulate the smaller json chunks\n",
    "json_chunks = splitter.split_json(json_data=json_data)\n",
    "\n",
    "for chunk in json_chunks[:3]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The splitter can also output documents\n",
    "docs = splitter.create_documents(texts=[json_data])\n",
    "\n",
    "for doc in docs[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a4d66-b470-404e-918b-6728df3b88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = splitter.split_text(json_data=json_data)\n",
    "\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef3195-375b-4db2-9804-f3fa5a249417",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(text) for text in texts][:10])\n",
    "print()\n",
    "print(texts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "992477c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = splitter.split_text(json_data=json_data, convert_lists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd43f6-78ab-4a73-853a-a777ab268efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(text) for text in texts][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(texts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at the documents\n",
    "docs[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
