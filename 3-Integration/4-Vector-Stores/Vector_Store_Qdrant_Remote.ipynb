{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-qdrant langchain langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -p 6333:6333 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 documents from the file.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize Hugging Face Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Replace with your desired model\n",
    "\n",
    "# Step 2: Load PDF and Split into Chunks\n",
    "loader = PyPDFLoader(\"../../00-example_data/layout-parser-paper.pdf\")\n",
    "pdf_docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(pdf_docs)} documents from the file.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    url=\"http://localhost:6333\",\n",
    "    collection_name=\"my_documents\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Similar Documents:\n",
      "1. In: International conference on machine learning. pp. 1180–1189. PMLR (2015)\n",
      "2. In: International conference on machine learning. pp. 1180–1189. PMLR (2015)\n",
      "3. 16 Z. Shen et al.\n",
      "[23] Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,\n",
      "Desmaison, A., Antiga, L., Lerer, A.: Automatic diﬀerentiation in pytorch (2017)\n",
      "[24] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,\n",
      "T., Lin, Z., Gimelshein, N., Antiga, L., et al.: Pytorch: An imperative style,\n",
      "high-performance deep learning library. arXiv preprint arXiv:1912.01703 (2019)\n",
      "[25] Pletschacher, S., Antonacopoulos, A.: The page (page analysis and ground-truth\n",
      "elements) format framework. In: 2010 20th International Conference on Pattern\n",
      "Recognition. pp. 257–260. IEEE (2010)\n",
      "[26] Prasad, D., Gadpal, A., Kapadni, K., Visave, M., Sultanpure, K.: Cascadetabnet:\n",
      "An approach for end to end table detection and structure recognition from image-\n",
      "based documents. In: Proceedings of the IEEE/CVF Conference on Computer\n",
      "Vision and Pattern Recognition Workshops. pp. 572–573 (2020)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Perform a Query\n",
    "query = \"What algorithm is discussed in the document?\"\n",
    "results = qdrant.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\nMost Similar Documents:\")\n",
    "for idx, result in enumerate(results, start=1):\n",
    "    print(f\"{idx}. {result.page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
