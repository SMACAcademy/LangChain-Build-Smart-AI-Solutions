{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-huggingface langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import getpass\n",
    "import os\n",
    "import time\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 documents from the file.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize Hugging Face Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Replace with your desired model\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Load PDF and Split into Chunks\n",
    "loader = PyPDFLoader(\"../../00-example_data/layout-parser-paper.pdf\")\n",
    "pdf_docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(pdf_docs)} documents from the file.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(pdf_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"langchain-test-index\",\n",
       "    \"dimension\": 384,\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"langchain-test-index-zhmtpmp.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"deletion_protection\": \"disabled\"\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents1 = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1c4a90fd-7a42-4d20-9388-88e42415e084',\n",
       " 'f6c621c3-b2c4-4ba4-80f5-583237e61447']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=documents1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b2de453b-e753-4191-af4b-d18803ca90da',\n",
       " '119f5b6a-dd6a-4207-b34a-9fd2568be618',\n",
       " '3012b3d5-936e-4966-8387-44393ce39061',\n",
       " 'b336b8ef-d33e-4a6c-8324-d909bea5c389',\n",
       " '6ec7c53c-f872-4e26-9d8a-536127b26f36',\n",
       " 'd1a71ec9-9ac3-4a03-b307-f02563090e75',\n",
       " 'f330f22d-4c8f-42ca-b2e5-6439e31268fd',\n",
       " '11c5e34c-164c-41e7-a275-024116654e3d',\n",
       " '95b24b26-36da-4a5e-86ce-50fb0103ac2d',\n",
       " 'e02cac47-90ff-45fc-9b68-189277b05b17',\n",
       " '3667e352-7d2b-471f-835b-d05d375dd01b',\n",
       " 'ce2ba2fd-08f0-46a5-ac51-c54a6ea004ca',\n",
       " 'f6356cd9-5c6f-480b-bfaf-b000ca227afb',\n",
       " '7412b7f5-be5b-4af5-a43a-cfa17e38fa79',\n",
       " '53868df4-0788-43f1-a275-028d07e92387',\n",
       " 'c0d21ac3-a74c-4ca5-9698-3a5288dce857',\n",
       " '84a20d28-ed06-4b60-859a-3210852e66e1',\n",
       " '04c30a73-ecb3-4168-8c26-ad897d0db8a8',\n",
       " 'df6bc58c-de2a-4e12-bac4-7d119b24709c',\n",
       " 'd81ee478-3cb6-4164-a025-2820c7dafb8f',\n",
       " 'b2db9a6e-2ba0-4967-8246-464e3eb45f70',\n",
       " 'af3b69b2-944c-4785-aa4e-0f926f07c7dd',\n",
       " 'd6a517d4-ce06-4e17-b0de-85df01851e28',\n",
       " 'c127f191-9363-46a4-a6bf-7502a8ce1fca',\n",
       " '4c834b3a-bdea-4c00-833b-a5e00068dde8',\n",
       " 'c48d5cb5-0717-4744-a365-556b2d4ca16f',\n",
       " '40230fe9-0dcc-4d5c-959f-269b8cc27b04',\n",
       " 'd7f75bb9-41a5-43c3-aaa5-2ea705f20431',\n",
       " '7c5efbe6-da04-4ba4-a26c-fbe6e65f4c86',\n",
       " '012dbbb7-7734-4cca-96f6-df145488d196',\n",
       " 'fe1e5092-5da7-4652-841e-ef3d49b6518a',\n",
       " '42a522b2-29db-47ca-b2e8-a6b713b62f3a',\n",
       " 'a56099d0-beeb-4364-86ed-357633cd698b',\n",
       " '2755e16e-3435-4f47-bb03-7fd214370623',\n",
       " '695b3d78-7133-4ef9-8c6e-66c9ffd404e1',\n",
       " '3a5e5bc6-1a9a-4050-ab78-1119ae3c7f49',\n",
       " '96c6a066-c062-4668-af86-37b87f9df573',\n",
       " 'd3463ff0-fd77-4261-81ab-3e04249a9623',\n",
       " 'fca43dfd-4e3a-4b60-9ce8-0b3b8dbfad12',\n",
       " '7f8c4824-d197-4252-b91b-af4994fef60d',\n",
       " '4c498b56-114c-4cc3-9646-6b9e0a1a1b2d',\n",
       " '566d951f-d025-44d2-aceb-f1a7f9d7a25c',\n",
       " '197b2726-7755-41b3-9b92-c61236ad2e70',\n",
       " '0fe4be36-c2b8-46f6-8f59-b0d90657637a',\n",
       " '2933f9bd-75fe-488a-99b5-bf76bd8ea682',\n",
       " '38766fc6-ec15-47bf-a013-f5f8d05f8eaf',\n",
       " '1df4e9c5-1666-42fb-9445-b699ba9d87ff',\n",
       " 'b0a91a97-3ce8-45a5-8748-23d6bc328eee',\n",
       " 'd38f2dbd-d2d1-4533-aed0-b567fee40c80',\n",
       " '54506284-0632-46de-a21c-2409df31598a',\n",
       " 'b655c7a5-8ff7-46b4-a343-f1f5dec728cd',\n",
       " '4f1b81c5-14c9-443d-8f5e-ad56c8d1a930',\n",
       " '2aa8ba1f-3a90-4a5d-8cf0-585d0d79da72']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "    {\n",
       "        \"name\": \"quickstart\",\n",
       "        \"dimension\": 2,\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"quickstart-zhmtpmp.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"deletion_protection\": \"disabled\"\n",
       "    },\n",
       "    {\n",
       "        \"name\": \"langchain-test-index\",\n",
       "        \"dimension\": 384,\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"langchain-test-index-zhmtpmp.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"deletion_protection\": \"disabled\"\n",
       "    }\n",
       "]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Similar Documents:\n",
      "1. to develop, and is robust to outliers. The DL models also generate ﬁne-grained\n",
      "results that enable creative approaches like page reorganization for OCR.\n",
      "16 This measures the overlap between the detected and ground-truth characters, and\n",
      "the maximum is 1.\n",
      "17 This measures the number of edits from the ground-truth text to the predicted text,\n",
      "and lower is better.\n",
      "2. rated by white spaces of variable size,\n",
      "and the vertical positions of objects\n",
      "can be an indicator of their layout\n",
      "type.\n",
      "15 A document page consists of eight rows like this. For simplicity we skip the row\n",
      "segmentation discussion and refer readers to the source code when available.\n",
      "3. 16 Z. Shen et al.\n",
      "[23] Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,\n",
      "Desmaison, A., Antiga, L., Lerer, A.: Automatic diﬀerentiation in pytorch (2017)\n",
      "[24] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,\n",
      "T., Lin, Z., Gimelshein, N., Antiga, L., et al.: Pytorch: An imperative style,\n",
      "high-performance deep learning library. arXiv preprint arXiv:1912.01703 (2019)\n",
      "[25] Pletschacher, S., Antonacopoulos, A.: The page (page analysis and ground-truth\n",
      "elements) format framework. In: 2010 20th International Conference on Pattern\n",
      "Recognition. pp. 257–260. IEEE (2010)\n",
      "[26] Prasad, D., Gadpal, A., Kapadni, K., Visave, M., Sultanpure, K.: Cascadetabnet:\n",
      "An approach for end to end table detection and structure recognition from image-\n",
      "based documents. In: Proceedings of the IEEE/CVF Conference on Computer\n",
      "Vision and Pattern Recognition Workshops. pp. 572–573 (2020)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Perform a Query\n",
    "query = \"logic in the document?\"\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\nMost Similar Documents:\")\n",
    "for idx, result in enumerate(results, start=1):\n",
    "    print(f\"{idx}. {result.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.312871] to develop, and is robust to outliers. The DL models also generate ﬁne-grained\n",
      "results that enable creative approaches like page reorganization for OCR.\n",
      "16 This measures the overlap between the detected and ground-truth characters, and\n",
      "the maximum is 1.\n",
      "17 This measures the number of edits from the ground-truth text to the predicted text,\n",
      "and lower is better. [{'page': 11.0, 'source': '../../00-example_data/layout-parser-paper.pdf'}]\n",
      "* [SIM=0.307854] rated by white spaces of variable size,\n",
      "and the vertical positions of objects\n",
      "can be an indicator of their layout\n",
      "type.\n",
      "15 A document page consists of eight rows like this. For simplicity we skip the row\n",
      "segmentation discussion and refer readers to the source code when available. [{'page': 10.0, 'source': '../../00-example_data/layout-parser-paper.pdf'}]\n",
      "* [SIM=0.281716] 16 Z. Shen et al.\n",
      "[23] Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,\n",
      "Desmaison, A., Antiga, L., Lerer, A.: Automatic diﬀerentiation in pytorch (2017)\n",
      "[24] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,\n",
      "T., Lin, Z., Gimelshein, N., Antiga, L., et al.: Pytorch: An imperative style,\n",
      "high-performance deep learning library. arXiv preprint arXiv:1912.01703 (2019)\n",
      "[25] Pletschacher, S., Antonacopoulos, A.: The page (page analysis and ground-truth\n",
      "elements) format framework. In: 2010 20th International Conference on Pattern\n",
      "Recognition. pp. 257–260. IEEE (2010)\n",
      "[26] Prasad, D., Gadpal, A., Kapadni, K., Visave, M., Sultanpure, K.: Cascadetabnet:\n",
      "An approach for end to end table detection and structure recognition from image-\n",
      "based documents. In: Proceedings of the IEEE/CVF Conference on Computer\n",
      "Vision and Pattern Recognition Workshops. pp. 572–573 (2020) [{'page': 15.0, 'source': '../../00-example_data/layout-parser-paper.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"logic in the document?\", k=3\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
