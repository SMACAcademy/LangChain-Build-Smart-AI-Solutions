{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-huggingface langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import getpass\n",
    "import os\n",
    "import time\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize Hugging Face Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Replace with your desired model\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 documents from the file.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load PDF and Split into Chunks\n",
    "loader = PyPDFLoader(\"../../00-example_data/layout-parser-paper.pdf\")\n",
    "pdf_docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(pdf_docs)} documents from the file.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"langchain-test-index\",\n",
       "    \"dimension\": 384,\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"langchain-test-index-zhmtpmp.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"deletion_protection\": \"disabled\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6a54fb4e-747c-4a29-91cc-3b8d55cacad3',\n",
       " 'e13c3999-e72b-43b1-aa98-d94305f89bcb',\n",
       " 'e73eb3e3-31d9-4574-9663-96d273dc1428',\n",
       " 'cdfee237-da6a-4030-83bf-2b98bc0abd20',\n",
       " '378bb921-3cd7-4b01-a63d-6a004375a499',\n",
       " 'aba94494-6d63-41ff-8867-122d725aef32',\n",
       " '62c60466-0137-47ef-b47c-e91fbd983e4a',\n",
       " '6afe1173-d853-44c3-9f77-53d4933dbab0',\n",
       " '08fea401-fe6c-469b-905a-33433e90ceab',\n",
       " '96b64907-b281-4adf-80cc-2bc5d396b965',\n",
       " 'f0ebab84-5db2-4b47-bba1-73b42196e459',\n",
       " 'f054aed6-9aa0-496c-994d-f02f7dfd4ae5',\n",
       " 'b96c782c-1113-4697-a198-222167ee32e2',\n",
       " '7621a5e9-d2c1-4ef7-89bb-c5944b046e22',\n",
       " 'b6aae1d2-e7ab-4d53-94c6-d53d1eac3fac',\n",
       " 'f067b340-2e6b-4991-9910-14e64513131a',\n",
       " '6833ad11-96a1-430c-9352-990eb8ff9622',\n",
       " '1ee004ea-a9dd-47cd-a022-291777c0aad2',\n",
       " '31e932c4-6d8f-4e8e-bce3-d7d99c9d5f41',\n",
       " 'b3e9889e-6ce6-4768-b0d5-902e63c86102',\n",
       " 'fc953d80-27cd-47cb-b5a9-62db28fde515',\n",
       " 'd6d91df3-7b17-46ae-85b5-a442d854bc21',\n",
       " '2a173659-194f-4fdc-b866-4e3491848083',\n",
       " '8ec40d87-a38c-43fb-908a-457a90c4bf17',\n",
       " '30ba69e4-c706-4158-9193-0a84a7cb50ea',\n",
       " '94f213c2-2a23-4166-aaf3-31977974f213',\n",
       " 'bbed9794-f7f1-4960-aa55-53a53098a40e',\n",
       " '7e5eae0a-1e09-4467-a0fe-1c4ec6b95a11',\n",
       " 'e62f8c56-842c-49c7-9062-cb17a956e3f5',\n",
       " 'd0122aff-5dfe-4571-b599-37eb3c92fa13',\n",
       " 'dd37ea26-8472-4d39-b98d-88298af78404',\n",
       " '22490815-3aed-4fc5-9135-16e14b71df20',\n",
       " '6ae333fd-bd15-486d-8c39-256669a57126',\n",
       " '059a1ca6-4edf-4141-a3ac-37b106d96a3b',\n",
       " '51ce9429-59a7-4160-b1fb-5656764359d5',\n",
       " '13108c87-dbe2-4b9b-97a5-aff480a9d0a7',\n",
       " 'eb6f12ce-19d5-4b65-9cbf-d46ecbe9a7cd',\n",
       " '389532e2-60e7-435f-8535-b506cc34cb69',\n",
       " '4ef17fac-73cf-49ca-91da-42dcddeaa9ff',\n",
       " '8ca8ebda-bbf2-47cc-9138-050987bb0fd8',\n",
       " '2bc724fb-e90d-4b1b-bf60-c5825e19927e',\n",
       " 'f5c8215f-fd5b-40f6-8c9b-7022c507e91c',\n",
       " 'e6b16584-05e8-4b56-a428-d2c373455f85',\n",
       " '6a42cf58-4bcb-4744-87b4-d45efdb66771',\n",
       " '90fe0cfa-9cfd-4ee9-bbd6-bc8620e0c2bb',\n",
       " 'a2a1209e-737e-4ae3-a9cb-8b40c12b7551',\n",
       " 'bb7c4e89-d5bd-4453-8744-aec52aea8135',\n",
       " '4098b290-7bfd-4f34-ae78-130a4e7a84c4',\n",
       " '7ca25c21-b491-4a65-aa7e-d28942340897',\n",
       " 'f6623dbe-c569-4b91-adb0-8da04edde186',\n",
       " '3f5a1e4d-fb44-4575-a866-b64d30067b14',\n",
       " '5f11fa25-8392-4355-954c-4de2240a07e2',\n",
       " 'c9770b82-f6b6-4a59-b4e6-bf00315cc149']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "    {\n",
       "        \"name\": \"quickstart\",\n",
       "        \"dimension\": 2,\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"quickstart-zhmtpmp.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"deletion_protection\": \"disabled\"\n",
       "    },\n",
       "    {\n",
       "        \"name\": \"langchain-test-index\",\n",
       "        \"dimension\": 384,\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"langchain-test-index-zhmtpmp.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"deletion_protection\": \"disabled\"\n",
       "    }\n",
       "]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Similar Documents:\n",
      "1. ument digitization pipelines. For example, sometimes the pipeline requires the\n",
      "combination of multiple DL models to achieve better accuracy. Currently, pipelines\n",
      "are mainly described in academic papers and implementations are often not pub-\n",
      "licly available. To this end, the LayoutParser community platform also enables\n",
      "the sharing of layout pipelines to promote the discussion and reuse of techniques.\n",
      "For each shared pipeline, it has a dedicated project page, with links to the source\n",
      "code, documentation, and an outline of the approaches. A discussion panel is\n",
      "provided for exchanging ideas. Combined with the core LayoutParser library,\n",
      "users can easily build reusable components based on the shared pipelines and\n",
      "apply them to solve their unique problems.\n",
      "5 Use Cases\n",
      "The core objective of LayoutParser is to make it easier to create both large-scale\n",
      "and light-weight document digitization pipelines. Large-scale document processing\n",
      "2. AllenNLP [8] and transformers [ 34] have provided the community with complete\n",
      "DL-based support for developing and deploying models for general computer\n",
      "vision and natural language processing problems. LayoutParser, on the other\n",
      "hand, specializes speciﬁcally in DIA tasks. LayoutParser is also equipped with a\n",
      "community platform inspired by established model hubs such as Torch Hub [23]\n",
      "and TensorFlow Hub [1]. It enables the sharing of pretrained models as well as\n",
      "full document processing pipelines that are unique to DIA tasks.\n",
      "There have been a variety of document data collections to facilitate the\n",
      "development of DL models. Some examples include PRImA [3](magazine layouts),\n",
      "PubLayNet [38](academic paper layouts), Table Bank [ 18](tables in academic\n",
      "papers), Newspaper Navigator Dataset [ 16, 17](newspaper ﬁgure layouts) and\n",
      "HJDataset [31](historical Japanese document layouts). A spectrum of models\n",
      "trained on these datasets are currently available in the LayoutParser model zoo\n",
      "3. The DocumentLayoutAnalysis project8 focuses on processing born-digital PDF\n",
      "documents via analyzing the stored PDF data. Repositories like DeepLayout9\n",
      "and Detectron2-PubLayNet10 are individual deep learning models trained on\n",
      "layout analysis datasets without support for the full DIA pipeline. The Document\n",
      "Analysis and Exploitation (DAE) platform [ 15] and the DeepDIVA project [ 2]\n",
      "aim to improve the reproducibility of DIA methods (or DL models), yet they\n",
      "are not actively maintained. OCR engines like Tesseract [14], easyOCR11 and\n",
      "paddleOCR12 usually do not come with comprehensive functionalities for other\n",
      "DIA tasks like layout analysis.\n",
      "Recent years have also seen numerous eﬀorts to create libraries for promoting\n",
      "reproducibility and reusability in the ﬁeld of DL. Libraries like Dectectron2 [ 35],\n",
      "6 The number shown is obtained by specifying the search type as ‘code’.\n",
      "7 https://ocr-d.de/en/about\n",
      "8 https://github.com/BobLd/DocumentLayoutAnalysis\n",
      "9 https://github.com/leonlulu/DeepLayout\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Perform a Query\n",
    "query = \"what is the use case being discussed in the documents?\"\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\nMost Similar Documents:\")\n",
    "for idx, result in enumerate(results, start=1):\n",
    "    print(f\"{idx}. {result.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.289667] ument digitization pipelines. For example, sometimes the pipeline requires the\n",
      "combination of multiple DL models to achieve better accuracy. Currently, pipelines\n",
      "are mainly described in academic papers and implementations are often not pub-\n",
      "licly available. To this end, the LayoutParser community platform also enables\n",
      "the sharing of layout pipelines to promote the discussion and reuse of techniques.\n",
      "For each shared pipeline, it has a dedicated project page, with links to the source\n",
      "code, documentation, and an outline of the approaches. A discussion panel is\n",
      "provided for exchanging ideas. Combined with the core LayoutParser library,\n",
      "users can easily build reusable components based on the shared pipelines and\n",
      "apply them to solve their unique problems.\n",
      "5 Use Cases\n",
      "The core objective of LayoutParser is to make it easier to create both large-scale\n",
      "and light-weight document digitization pipelines. Large-scale document processing [{'page': 9.0, 'source': '../../00-example_data/layout-parser-paper.pdf'}]\n",
      "* [SIM=0.274021] AllenNLP [8] and transformers [ 34] have provided the community with complete\n",
      "DL-based support for developing and deploying models for general computer\n",
      "vision and natural language processing problems. LayoutParser, on the other\n",
      "hand, specializes speciﬁcally in DIA tasks. LayoutParser is also equipped with a\n",
      "community platform inspired by established model hubs such as Torch Hub [23]\n",
      "and TensorFlow Hub [1]. It enables the sharing of pretrained models as well as\n",
      "full document processing pipelines that are unique to DIA tasks.\n",
      "There have been a variety of document data collections to facilitate the\n",
      "development of DL models. Some examples include PRImA [3](magazine layouts),\n",
      "PubLayNet [38](academic paper layouts), Table Bank [ 18](tables in academic\n",
      "papers), Newspaper Navigator Dataset [ 16, 17](newspaper ﬁgure layouts) and\n",
      "HJDataset [31](historical Japanese document layouts). A spectrum of models\n",
      "trained on these datasets are currently available in the LayoutParser model zoo [{'page': 3.0, 'source': '../../00-example_data/layout-parser-paper.pdf'}]\n",
      "* [SIM=0.266053] The DocumentLayoutAnalysis project8 focuses on processing born-digital PDF\n",
      "documents via analyzing the stored PDF data. Repositories like DeepLayout9\n",
      "and Detectron2-PubLayNet10 are individual deep learning models trained on\n",
      "layout analysis datasets without support for the full DIA pipeline. The Document\n",
      "Analysis and Exploitation (DAE) platform [ 15] and the DeepDIVA project [ 2]\n",
      "aim to improve the reproducibility of DIA methods (or DL models), yet they\n",
      "are not actively maintained. OCR engines like Tesseract [14], easyOCR11 and\n",
      "paddleOCR12 usually do not come with comprehensive functionalities for other\n",
      "DIA tasks like layout analysis.\n",
      "Recent years have also seen numerous eﬀorts to create libraries for promoting\n",
      "reproducibility and reusability in the ﬁeld of DL. Libraries like Dectectron2 [ 35],\n",
      "6 The number shown is obtained by specifying the search type as ‘code’.\n",
      "7 https://ocr-d.de/en/about\n",
      "8 https://github.com/BobLd/DocumentLayoutAnalysis\n",
      "9 https://github.com/leonlulu/DeepLayout [{'page': 2.0, 'source': '../../00-example_data/layout-parser-paper.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"what is use case being discussed in the documents?\", k=3\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
