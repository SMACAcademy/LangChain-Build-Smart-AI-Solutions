{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\n",
    "\n",
    "from openinference.instrumentation import using_attributes\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider = trace_sdk.TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\n",
    "\n",
    "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import phoenix as px\n",
    "\n",
    "os.environ[\"PHOENIX_TRACING\"] = \"true\"\n",
    "px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muthu\\AppData\\Local\\Temp\\ipykernel_1956\\1127603484.py:26: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm = LLMChain(llm=llmmodel, prompt=prompt, metadata={\"category\": \"jokes\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ChatOllama\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x57d98f08c84310cd8d7e2dc2cbd3cbae\",\n",
      "        \"span_id\": \"0xdd54f7a9e8e93857\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x8041c0a5849822f3\",\n",
      "    \"start_time\": \"2025-02-06T07:02:58.855861Z\",\n",
      "    \"end_time\": \"2025-02-06T07:03:00.665872Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"session.id\": \"my-test-session\",\n",
      "        \"user.id\": \"my-test-user\",\n",
      "        \"tag.tags\": [\n",
      "            \"tag-1\",\n",
      "            \"tag-2\"\n",
      "        ],\n",
      "        \"llm.prompt_template.template\": \"Who won the soccer match in {city} on {date}\",\n",
      "        \"llm.prompt_template.version\": \"v1.0\",\n",
      "        \"llm.prompt_template.variables\": \"{\\\"city\\\": \\\"Johannesburg\\\", \\\"date\\\": \\\"July 11th\\\"}\",\n",
      "        \"input.value\": \"{\\\"messages\\\": [[{\\\"lc\\\": 1, \\\"type\\\": \\\"constructor\\\", \\\"id\\\": [\\\"langchain\\\", \\\"schema\\\", \\\"messages\\\", \\\"HumanMessage\\\"], \\\"kwargs\\\": {\\\"content\\\": \\\"Tell me a funny joke\\\", \\\"type\\\": \\\"human\\\"}}]]}\",\n",
      "        \"input.mime_type\": \"application/json\",\n",
      "        \"output.value\": \"{\\\"generations\\\": [[{\\\"text\\\": \\\"Here's one:\\\\n\\\\nWhat do you call a fake noodle?\\\\n\\\\nAn impasta!\\\\n\\\\nI hope that made you laugh! Do you want to hear another one?\\\", \\\"generation_info\\\": {\\\"model\\\": \\\"llama3.2:latest\\\", \\\"created_at\\\": \\\"2025-02-06T07:03:00.6638176Z\\\", \\\"done\\\": true, \\\"done_reason\\\": \\\"stop\\\", \\\"total_duration\\\": 1804914200, \\\"load_duration\\\": 1377083600, \\\"prompt_eval_count\\\": 30, \\\"prompt_eval_duration\\\": 148000000, \\\"eval_count\\\": 33, \\\"eval_duration\\\": 277000000, \\\"message\\\": {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"\\\", \\\"images\\\": null, \\\"tool_calls\\\": null}}, \\\"type\\\": \\\"ChatGeneration\\\", \\\"message\\\": {\\\"lc\\\": 1, \\\"type\\\": \\\"constructor\\\", \\\"id\\\": [\\\"langchain\\\", \\\"schema\\\", \\\"messages\\\", \\\"AIMessage\\\"], \\\"kwargs\\\": {\\\"content\\\": \\\"Here's one:\\\\n\\\\nWhat do you call a fake noodle?\\\\n\\\\nAn impasta!\\\\n\\\\nI hope that made you laugh! Do you want to hear another one?\\\", \\\"response_metadata\\\": {\\\"model\\\": \\\"llama3.2:latest\\\", \\\"created_at\\\": \\\"2025-02-06T07:03:00.6638176Z\\\", \\\"done\\\": true, \\\"done_reason\\\": \\\"stop\\\", \\\"total_duration\\\": 1804914200, \\\"load_duration\\\": 1377083600, \\\"prompt_eval_count\\\": 30, \\\"prompt_eval_duration\\\": 148000000, \\\"eval_count\\\": 33, \\\"eval_duration\\\": 277000000, \\\"message\\\": {\\\"lc\\\": 1, \\\"type\\\": \\\"not_implemented\\\", \\\"id\\\": [\\\"ollama\\\", \\\"_types\\\", \\\"Message\\\"], \\\"repr\\\": \\\"Message(role='assistant', content='', images=None, tool_calls=None)\\\"}}, \\\"type\\\": \\\"ai\\\", \\\"id\\\": \\\"run-52949b7e-4474-44eb-8782-8d763830f496-0\\\", \\\"usage_metadata\\\": {\\\"input_tokens\\\": 30, \\\"output_tokens\\\": 33, \\\"total_tokens\\\": 63}, \\\"tool_calls\\\": [], \\\"invalid_tool_calls\\\": []}}}]], \\\"llm_output\\\": null, \\\"run\\\": null, \\\"type\\\": \\\"LLMResult\\\"}\",\n",
      "        \"output.mime_type\": \"application/json\",\n",
      "        \"llm.input_messages.0.message.role\": \"user\",\n",
      "        \"llm.input_messages.0.message.content\": \"Tell me a funny joke\",\n",
      "        \"llm.output_messages.0.message.role\": \"assistant\",\n",
      "        \"llm.output_messages.0.message.content\": \"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\\n\\nI hope that made you laugh! Do you want to hear another one?\",\n",
      "        \"llm.invocation_parameters\": \"{\\\"_type\\\": \\\"chat-ollama\\\", \\\"stop\\\": null}\",\n",
      "        \"llm.token_count.prompt\": 30,\n",
      "        \"llm.token_count.completion\": 33,\n",
      "        \"llm.token_count.total\": 63,\n",
      "        \"metadata\": \"{\\\"ls_provider\\\": \\\"ollama\\\", \\\"ls_model_name\\\": \\\"llama3.2:latest\\\", \\\"ls_model_type\\\": \\\"chat\\\", \\\"ls_temperature\\\": 0.0}\",\n",
      "        \"openinference.span.kind\": \"LLM\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.29.0\",\n",
      "            \"service.name\": \"unknown_service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"LLMChain\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x57d98f08c84310cd8d7e2dc2cbd3cbae\",\n",
      "        \"span_id\": \"0x8041c0a5849822f3\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-02-06T07:02:58.853864Z\",\n",
      "    \"end_time\": \"2025-02-06T07:03:00.672872Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"session.id\": \"my-test-session\",\n",
      "        \"user.id\": \"my-test-user\",\n",
      "        \"tag.tags\": [\n",
      "            \"tag-1\",\n",
      "            \"tag-2\"\n",
      "        ],\n",
      "        \"llm.prompt_template.template\": \"Who won the soccer match in {city} on {date}\",\n",
      "        \"llm.prompt_template.version\": \"v1.0\",\n",
      "        \"llm.prompt_template.variables\": \"{\\\"city\\\": \\\"Johannesburg\\\", \\\"date\\\": \\\"July 11th\\\"}\",\n",
      "        \"input.value\": \"{\\\"adjective\\\": \\\"funny\\\", \\\"metadata\\\": {\\\"variant\\\": \\\"funny\\\"}}\",\n",
      "        \"input.mime_type\": \"application/json\",\n",
      "        \"output.value\": \"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\\n\\nI hope that made you laugh! Do you want to hear another one?\",\n",
      "        \"metadata\": \"{\\\"category\\\": \\\"jokes\\\"}\",\n",
      "        \"openinference.span.kind\": \"CHAIN\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.29.0\",\n",
      "            \"service.name\": \"unknown_service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "Here's one:\n",
      "\n",
      "What do you call a fake noodle?\n",
      "\n",
      "An impasta!\n",
      "\n",
      "I hope that made you laugh! Do you want to hear another one?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with using_attributes(\n",
    "        session_id=\"my-test-session\",\n",
    "        user_id=\"my-test-user\",\n",
    "        metadata={\n",
    "            \"test-int\": 1,\n",
    "            \"test-str\": \"string\",\n",
    "            \"test-list\": [1, 2, 3],\n",
    "            \"test-dict\": {\n",
    "                \"key-1\": \"val-1\",\n",
    "                \"key-2\": \"val-2\",\n",
    "            },\n",
    "        },\n",
    "        prompt_template=\"Who won the soccer match in {city} on {date}\",\n",
    "        prompt_template_version=\"v1.0\",\n",
    "        prompt_template_variables={\n",
    "            \"city\": \"Johannesburg\",\n",
    "            \"date\": \"July 11th\",\n",
    "        },\n",
    "        tags=[\"tag-1\", \"tag-2\"],\n",
    "    ):\n",
    "        prompt_template = \"Tell me a {adjective} joke\"\n",
    "        prompt = PromptTemplate(input_variables=[\"adjective\"], template=prompt_template)\n",
    "\n",
    "        llmmodel = ChatOllama(model=\"llama3.2:latest\", temperature=0)\n",
    "        llm = LLMChain(llm=llmmodel, prompt=prompt, metadata={\"category\": \"jokes\"})\n",
    "        completion = llm.predict(adjective=\"funny\", metadata={\"variant\": \"funny\"})\n",
    "        print(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
